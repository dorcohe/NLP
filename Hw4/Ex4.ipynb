{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#train_path = '/data/home/dor/train'\n#eval_path = '/data/home/dor/eval'\n#model_path = '/data/home/dor/model'\ntrain_path = 'train'\neval_path = 'eval'\nmodel_path ='model'",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import deque\nfrom gensim.models import Word2Vec\nfrom sklearn import svm\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport numpy as np\nimport random",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def conll_to_transitions(sentence):\n    '''\n    Given a sentence, returns a list of transitions.\n    Each transition is a training instance for your classifier. A transition \n    is composed of the following 4 items:\n    - first word in stack\n    - second word in stack (could be None is stack is of size=1)\n    - first word in buffer (could be None if the buffer is empty)\n    - the transition label (SHIFT, LEFT, RIGHT)\n    '''\n    s = []  #stack\n    b = deque([])  #buffer\n\n    transitions = []\n\n    for w in sentence:\n        b.append(w)\n\n    s.append(['0', 'ROOT', '_', '_', '_', '_', '0', '_', '_', '_'])\n\n    while len(b) > 0 or len(s) > 1:\n        if s[-1][0] == '0':   # the root\n            add_shift(s, b, transitions)\n        elif s[-2][6] == s[-1][0] and check_rightest_arc(s[-2], b):\n            add_left(s, b, transitions)\n        elif s[-1][6] == s[-2][0] and (len(b) == 0 or s[-2][0] != '0') and check_rightest_arc(s[-1], b):\n            add_right(s, b, transitions)\n        elif len(b) == 0:\n            #print(\"Non projective\")\n            return None\n        else:\n            add_shift(s, b, transitions)\n    return transitions\n\n\ndef check_rightest_arc(word, b):\n    '''\n   w[6] is the index of the head of \"this\" word, so in this method we check\n   if there is an arc that goes from one of the words in the buffer\n   to \"word\" (which exists in the stack)\n    '''\n    for w in b:\n        if w[6] == word[0]:\n            return False\n    return True\n\n\ndef add_shift(s, b, transitions):\n    '''\n    Adding shift transition\n    '''\n    word = b.popleft()\n    top2 = None\n    if len(s) > 1:\n        top2 = s[-2]\n    transitions.append([s[-1], top2, word, 'SHIFT'])\n    s.append(word)\n\n\ndef add_left(s, b, transitions):\n    '''\n    Adding left transition\n    '''\n    top1 = s.pop()\n    top2 = s.pop()\n    transitions.append([top1, top2, b[0] if len(b) > 0 else None, 'LEFT'])\n    s.append(top1)\n\n\ndef add_right(s, b, transitions):\n    '''\n    Adding right transition\n    '''\n    top1 = s.pop()\n    top2 = s.pop()\n    transitions.append([top1, top2, b[0] if len(b) > 0 else None, 'RIGHT'])\n    s.append(top2)\n\n    \ndef transitions_to_conll(sentence, predicted_transitions, real_transitions):\n    s = [0]\n    b = deque([])\n    result = {}\n    for word in sentence:\n        b.append(word)\n    total = len(predicted_transitions)\n    counter = 0\n    while len(s) > 1 or len(b)>0:\n        if len(predicted_transitions)>0:\n            predicted_trans = predicted_transitions[0]\n            real_trans = real_transitions[0][3]\n            del predicted_transitions[0]\n            del real_transitions[0]\n        else:\n            predicted_trans = None\n        if predicted_trans == 'SHIFT' and not b:\n            rand = random.uniform(0, 1)\n            if (rand<=0.5):\n                predicted_trans = 'LEFT'\n            else:\n                predicted_trans = 'RIGHT'\n        if len(s) < 2 and b:\n            predicted_trans = 'SHIFT'\n        elif len(s) < 2:\n            predicted_trans = 'RIGHT'\n\n        if (predicted_trans == real_trans):\n            counter += 1\n        \n        if predicted_trans == 'LEFT':\n            t1 = s.pop()\n            t2 = s.pop()\n            result[t2]= t1\n            s.append(t1)\n        elif predicted_trans == 'SHIFT':\n            s.append(b.popleft())\n        elif predicted_trans == 'RIGHT':\n            t1 = s.pop()\n            t2 = s.pop()\n            result[t1] = t2\n            s.append(t2)\n        \n        \n    return result, counter/total\n            \n            \n    \n    \n",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_trans_list(input_file):\n    h = open(input_file, 'r')\n    sentence = []\n    trans_list = []\n    for l in h:\n        l = l.strip()\n        if l == \"\":\n            trans = conll_to_transitions(sentence)\n            trans_list.append(trans)\n            #print(\"NEW\")\n            #print(trans)\n            sentence = []\n        else:\n            sentence.append(l.split('\\t'))\n    h.close()\n    return trans_list\n\ntrain_trans_list = get_trans_list(train_path)\neval_trans_kist = get_trans_list(eval_path)\nprint(train_trans_list[1][1])",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[['1', 'The', '_', 'DT', 'DT', '_', '4', 'NMOD', '_', '_'], ['0', 'ROOT', '_', '_', '_', '_', '0', '_', '_', '_'], ['2', 'current', '_', 'JJ', 'JJ', '_', '4', 'NMOD', '_', '_'], 'SHIFT']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Creating word embbidings "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_sentences(files):\n    ### return word2vec model using the train file\n    sentences_list = []\n    for file in files:\n        h = open(file, 'r')\n        sentence = ['ROOT']\n        for l in h:\n            l = l.strip()\n            if l == \"\":\n                sentences_list.append(sentence)\n                sentence = ['ROOT']\n            else:\n                sentence.append(l.split('\\t')[1])\n        h.close()\n    return sentences_list",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentences = get_sentences([train_path, eval_path])\nword2vec_model = Word2Vec(sentences, window=7, min_count=1)\nword2vec_model.save(model_path)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Finding POS coarse version and POS tag more specific"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_pos_set(input_file):\n    h = open(input_file, 'r')\n    POS_coarse_version = set()\n    POS_more_specific = set()\n    for l in h:\n        l = l.strip()\n        if l == \"\":\n            continue\n        else:\n            l_split = l.split('\\t')\n            if l_split[3] != \"_\":\n                POS_coarse_version.add(l_split[3])\n            if l_split[4] != \"_\":\n                POS_more_specific.add(l_split[4])\n    h.close()\n    return list(POS_coarse_version), list(POS_more_specific)\n\nPOS_coarse_version,POS_more_specific = get_pos_set(train_path)\nprint('POS_coarse_version ' + str(POS_coarse_version))\nprint('POS_more_specific ' + str(POS_more_specific))",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "POS_coarse_version ['NN', ')', '$', 'CD', '.', 'IN', 'UH', 'PR', 'TO', 'WD', 'PD', 'PO', '``', 'VB', \"''\", ',', 'WR', 'DT', 'WP', 'MD', 'CC', 'JJ', 'RB', 'FW', ':', 'EX', '(', 'RP']\nPOS_more_specific ['NN', 'VBP', ')', '$', 'CD', 'JJR', '.', 'IN', 'UH', 'TO', 'PRP', 'NNS', 'VBG', 'RBR', '``', 'WDT', 'VB', \"''\", ',', 'VBD', 'NNP', 'POS', 'DT', 'WP$', 'RBS', 'WP', 'MD', 'CC', 'JJS', 'JJ', 'RB', 'FW', 'WRB', ':', 'EX', 'PRP$', '(', 'VBZ', 'VBN', 'PDT', 'RP', 'NNPS']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# implementing approch 1"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "First, we create tran to vector using the following features:\n* The two top words in the stack - presnted as word2vec\n* The top word in the buffer - presnted as word2vec\n* The POS of each word, as 1 vector - we use both coarse and more specific. We use 1 hot vector \n\nThe following method return for each trans state: the training vector and the operation needed to be done in Nivre-Acr \n  standard {'SHIFT':0,'LEFT':1,'RIGHT':2}"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def trans_to_train_vec_and_result(trans_row, POS_coarse_version, POS_more_specific, model):\n    word2vec_size = model.vector_size\n    POS_cv_len = len(POS_coarse_version)\n    POS_ms_len = len(POS_more_specific)\n    vector_size = 3*word2vec_size + 3*POS_cv_len + 3*POS_ms_len + 3\n    i=0\n    label_dict = {'SHIFT' : 0, 'LEFT' : '1', 'RIGHT': 2}\n    x = np.zeros(vector_size)\n    for row in trans_row:\n        if i==3:\n            y = label_dict[row]\n            continue\n        else:\n            if (row != None):\n                word = row[1]\n                if (word == 'ROOT'):\n                    word2vec = model.wv.get_vector(word)\n                    POS_coarse_vec = np.zeros(POS_cv_len)\n                    POS_more_specific_vec = np.zeros(POS_ms_len)\n                else:\n                    word2vec = model.wv.get_vector(word)\n                    POS_coarse_vec = np.zeros(POS_cv_len)\n                    np.put(POS_coarse_vec, POS_coarse_version.index(row[3]),1)\n                    POS_more_specific_vec = np.zeros(POS_ms_len)\n                    np.put(POS_more_specific_vec, POS_more_specific.index(row[4]),1)\n            else:\n                i = i + 1 \n                continue\n        x[i*word2vec_size : (i+1)*word2vec_size] = word2vec\n        x[i*POS_cv_len + 3*word2vec_size : (i+1)*POS_cv_len + 3*word2vec_size] = POS_coarse_vec\n        x[i*POS_ms_len + 3*word2vec_size + 3*POS_cv_len : (i+1)*POS_ms_len + 3*word2vec_size + 3*POS_cv_len ] = POS_more_specific_vec\n        x[-3+i] =  int(row[0]) \n        \n       \n        i = i + 1 \n    return x,y \n    ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's statrt to train our ML model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "word2vec_size = word2vec_model.vector_size\nPOS_cv_len = len(POS_coarse_version)\nPOS_ms_len = len(POS_more_specific)\nvector_size = 3*word2vec_size + 3*POS_cv_len+3*POS_ms_len + 3\nX = np.empty((50000, vector_size), float)\nY = np.empty((50000,1))\ni = 0\nfor z in train_trans_list[1:]:\n    if not z == None:\n        for tri in z:\n            x,y = trans_to_train_vec_and_result(tri, POS_coarse_version, POS_more_specific, word2vec_model)\n            X[i] = x\n            Y[i] = y\n            i = i + 1\nX = X[0:i-1, :]\nY = Y[0:i-1, :]",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## evalute: "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "Let's try KNN"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(Y.ravel().shape)",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(44019,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for k in range(3,13,2):\n    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n    knn.fit(X, Y.ravel())\n    index_dict = {0:'SHIFT',1:'LEFT',2:'RIGHT'}\n    count = 0\n    total = 0\n    classifier_eval = 0\n    sentence = []\n    predicted_transiation = []\n    h = open(eval_path, 'r')\n    for l in h:\n        l = l.strip()\n        if l == \"\":\n            real_transiation = conll_to_transitions(sentence)\n            if real_transiation == None:\n                continue\n            for word in real_transiation:\n                x,y = trans_to_train_vec_and_result(word, POS_coarse_version, POS_more_specific, word2vec_model)\n                x = x.reshape(1, -1)\n                predicted_trans = index_dict[int(knn.predict(x)[0])]\n                predicted_transiation.append(predicted_trans)\n            dictOfWords = { i+1 : sentence[i][1] for i in range(0, len(sentence) ) }  \n            results, acc = transitions_to_conll(dictOfWords, predicted_transiation, real_transiation)\n            \n            for word in sentence:\n                if  word[6] != \"_\":\n                    if int(word[0]) in results and results[int(word[0])] == int(word[6]):\n                          count = count + 1\n            classifier_eval += acc * len(sentence)\n            total = total + len(sentence)\n            sentence = []\n            svm_transition = []     \n        else:\n            sentence.append(l.split('\\t'))\n    h.close()\n    print(\"Total accuracy of the classifier for k =\" + str(k) + \" is: \" + str(classifier_eval/total))\n    print(\"Total accuracy of matching word for k =\" + str(k) + \" is: \" + str(count/total))",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Total accuracy of the classifier for k =3 is: 0.7980910425844346\nTotal accuracy of matching word for k =3 is: 0.30983847283406757\nTotal accuracy of the classifier for k =5 is: 0.7856093979441997\nTotal accuracy of matching word for k =5 is: 0.2878120411160059\nTotal accuracy of the classifier for k =7 is: 0.7878120411160059\nTotal accuracy of matching word for k =7 is: 0.302496328928047\nTotal accuracy of the classifier for k =9 is: 0.7966226138032305\nTotal accuracy of matching word for k =9 is: 0.33480176211453744\nTotal accuracy of the classifier for k =11 is: 0.7929515418502202\nTotal accuracy of matching word for k =11 is: 0.3054331864904552\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see that the classifier is right about 80% of the cases.\nHowever, only 30% of the words are matched correctly because one error in classification can effect the following words."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}