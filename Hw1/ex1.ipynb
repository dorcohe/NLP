{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Homework Assiagment 1 - NLP\n\n## Dor Cohen 302577820"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Part 1: \n\nWrite a function lm that generates a language model\tover characters from a textual corpus.\t"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## here we import staff\nfrom itertools import groupby\nfrom numpy import log2",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#### Helpers methods\ndef n_grams_characters(text, n):\n    return [text[i:i+n] for i in range(len(text)-n+1)]\n\ndef get_ngrams_dic(grams):\n    dic = {}\n    for g in grams:\n        if g in dic:\n            dic[g] = dic[g] + 1\n        else:\n            dic[g] = 1\n    return dic\n\ndef write_values_to_file(f, grams_dic, n, prefix_grams_dic={}, total = 0):\n    if (n==1):\n        f.write(\"<unk>\" +'\\t' + str(log2(1/(len(grams_dic) + total))) + '\\n') #bounus \n        for k,v in grams_dic.items():\n            f.write(str(k) +'\\t' + str(log2((v+1)/(total + len(grams_dic)))) + '\\n')\n        return\n    for k,v in grams_dic.items():\n        f.write(str(k) +'\\t'+ str(log2(v/prefix_grams_dic[k[0:n-1]])) + '\\n')\n    \n        \n",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#The requsted method\ndef lm(corpus_file, model_file):\n    with open(corpus_file, 'r') as f:\n        corpus = f.read().lower()\n        grams3 = n_grams_characters(corpus, 3)\n        grams2 = n_grams_characters(corpus, 2)\n        grams1 = n_grams_characters(corpus, 1)\n        grams1Dic = get_ngrams_dic(grams1)\n        grams2Dic = get_ngrams_dic(grams2)\n        grams3Dic = get_ngrams_dic(grams3)\n    with open(model_file,'w+') as f:\n        f.write('3-grams:\\n')\n        write_values_to_file(f, grams3Dic,  3, prefix_grams_dic=grams2Dic)\n        f.write('2-grams:\\n')\n        write_values_to_file(f, grams2Dic, 2, prefix_grams_dic=grams1Dic )\n        f.write('1-grams:\\n')\n        write_values_to_file(f, grams1Dic, 1, total = len(corpus))\n    \n    ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Part 2:\nWrite\ta function eval that calculates and\tprints the perplexity of a model running over a\t\ngiven text.\t\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_dics_from_model_file(f):\n    dict3 = {}\n    dict2 = {}\n    dict1 = {}\n    lines = f.readlines()\n    backslash_n_flag = False\n    i = 3\n    for line in lines:\n        line = line.rstrip('\\n')\n        if line == '3-grams:':\n            i = 3\n            continue\n        elif line == '2-grams:':\n            i = 2\n            continue\n        elif line == '1-grams:':\n            i = 1\n            continue\n        if backslash_n_flag:\n            line = '\\n' + line\n            backslash_n_flag = False\n        if line.find('\\t')==-1:\n            backslash_n_flag = True\n            continue\n        \n        line = line.split('\\t')\n        if (i==3):\n            dict3[line[0]] = float(line[1])\n        elif (i==2):\n            dict2[line[0]] = float(line[1])\n        elif (i==1):\n            dict1[line[0]] = float(line[1])\n    return [dict3, dict2 , dict1]",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def eval(input_file, model_file, weights):\n    with open(model_file, 'r') as f:\n        dict3, dict2, dict1 = get_dics_from_model_file(f)\n    with open(input_file, 'r') as f:\n        text = f.read().lower()\n        grams = n_grams_characters(text, 3)\n        interpolation_dic = {}\n        lambda1, lambda2, lambda3 = weights\n        sum1 = 0\n        for gram in grams:\n            P = 0\n            if (gram[2:3] in dict1):\n                P += lambda3*2**(dict1[gram[2:3]])\n            else:\n                P += lambda3*2**(dict1['<unk>']) #bonus\n            if (gram[1:3] in dict2):\n                P += lambda2*2**(dict2[gram[1:3]])\n            if (gram in dict3):\n                P += lambda1*2**(dict3[gram])\n            sum1 += log2(P)\n        return 2**((-sum1/len(text)))\n       \n            \n            \n            \n        ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Part 3:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "I will use escape characteres that will indicate EOL and BOL. EOL = '\\a' and BOL = '\\b'."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "languages = [\"en\", 'es', 'fr', 'in', 'it', 'nl', 'pt', 'tl']\nlanguages_dict = {}\nfor lan in languages:\n    data = pd.read_csv(lan + '.csv')\n    data = data.drop(\"tweet_id\", axis=1)\n    data['tweet_text'] = '\\b' + data['tweet_text'].astype(str) + '\\a'\n    train = data.sample(frac=0.9,random_state=50)\n    test = data.drop(train.index)\n    languages_dict[lan] = [train, test]",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def add_to_file(x,f):\n    f.write(x['tweet_text'])\nfor lan in languages:\n    input_file_name = lan + '_train.txt'\n    model_file_name = lan + '_model.txt'\n    with open(input_file_name, 'w+') as f:\n        train = languages_dict[lan][0]\n        train.apply(lambda x: add_to_file(x,f), axis=1)\n    lm(input_file_name, model_file_name)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "table = np.empty((len(languages)+1, len(languages)+1), dtype=object)\ntable[0,1:len(languages)+1] = languages\ntable[1:len(languages)+1,0] = languages\nfor i in range(1, len(languages)+1):\n    for j in range(1, len(languages)+1):\n        model_file_name = languages[i-1] + '_model.txt'\n        input_file_name = languages[j-1] + '_test.txt'\n        with open(input_file_name, 'w+') as f:\n            test = languages_dict[languages[j-1]][1]\n            test.apply(lambda x: add_to_file(x,f), axis=1)\n        result = eval(input_file_name,model_file_name, [0.4, 0.3, 0.3])\n        table[i,j] = str(result)\n",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results = pd.DataFrame (table)\nresults",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n      <td>en</td>\n      <td>es</td>\n      <td>fr</td>\n      <td>in</td>\n      <td>it</td>\n      <td>nl</td>\n      <td>pt</td>\n      <td>tl</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>en</td>\n      <td>12.076535229087849</td>\n      <td>17.994538689422196</td>\n      <td>18.55557944197081</td>\n      <td>18.539363028422635</td>\n      <td>17.052876790133404</td>\n      <td>16.701247898511934</td>\n      <td>19.748179201333276</td>\n      <td>17.33174171993408</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>es</td>\n      <td>17.57630481796407</td>\n      <td>11.49330046774936</td>\n      <td>17.417151472296506</td>\n      <td>19.41609105716152</td>\n      <td>15.20595659665287</td>\n      <td>18.425598320833235</td>\n      <td>15.454487798509813</td>\n      <td>19.0554785893154</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fr</td>\n      <td>16.651978181563926</td>\n      <td>16.62550893891067</td>\n      <td>11.824844741116152</td>\n      <td>19.696575869914657</td>\n      <td>15.897706339073602</td>\n      <td>17.49529282958224</td>\n      <td>17.864357523914652</td>\n      <td>19.64097804287586</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in</td>\n      <td>17.104556657238035</td>\n      <td>19.41460067477763</td>\n      <td>21.795873060736664</td>\n      <td>12.666240406715083</td>\n      <td>17.919444583945772</td>\n      <td>18.08236675953222</td>\n      <td>21.040912553984587</td>\n      <td>15.907320810732944</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>it</td>\n      <td>17.30483456028146</td>\n      <td>15.481373460361235</td>\n      <td>17.470436828329948</td>\n      <td>19.536559609238644</td>\n      <td>11.468008642978926</td>\n      <td>18.71583919074696</td>\n      <td>16.524258037845925</td>\n      <td>17.98548138095934</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>nl</td>\n      <td>16.221777980937997</td>\n      <td>18.699089497023447</td>\n      <td>18.389487732941827</td>\n      <td>18.722416226615508</td>\n      <td>18.271995272683895</td>\n      <td>12.371159453262619</td>\n      <td>20.063652347231066</td>\n      <td>18.27024174892468</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>pt</td>\n      <td>17.785133084964095</td>\n      <td>14.400730688176896</td>\n      <td>17.80350295442515</td>\n      <td>19.872894489006402</td>\n      <td>15.871853912506372</td>\n      <td>19.100671273999616</td>\n      <td>11.334996708770838</td>\n      <td>18.78590479935641</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>tl</td>\n      <td>15.979584895763255</td>\n      <td>17.832543583289866</td>\n      <td>21.21780830649941</td>\n      <td>16.09128287286364</td>\n      <td>17.268251707260934</td>\n      <td>18.331957869293</td>\n      <td>19.641922538006423</td>\n      <td>11.793184868148634</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "      0                   1                   2                   3  \\\n0  None                  en                  es                  fr   \n1    en  12.076535229087849  17.994538689422196   18.55557944197081   \n2    es   17.57630481796407   11.49330046774936  17.417151472296506   \n3    fr  16.651978181563926   16.62550893891067  11.824844741116152   \n4    in  17.104556657238035   19.41460067477763  21.795873060736664   \n5    it   17.30483456028146  15.481373460361235  17.470436828329948   \n6    nl  16.221777980937997  18.699089497023447  18.389487732941827   \n7    pt  17.785133084964095  14.400730688176896   17.80350295442515   \n8    tl  15.979584895763255  17.832543583289866   21.21780830649941   \n\n                    4                   5                   6  \\\n0                  in                  it                  nl   \n1  18.539363028422635  17.052876790133404  16.701247898511934   \n2   19.41609105716152   15.20595659665287  18.425598320833235   \n3  19.696575869914657  15.897706339073602   17.49529282958224   \n4  12.666240406715083  17.919444583945772   18.08236675953222   \n5  19.536559609238644  11.468008642978926   18.71583919074696   \n6  18.722416226615508  18.271995272683895  12.371159453262619   \n7  19.872894489006402  15.871853912506372  19.100671273999616   \n8   16.09128287286364  17.268251707260934     18.331957869293   \n\n                    7                   8  \n0                  pt                  tl  \n1  19.748179201333276   17.33174171993408  \n2  15.454487798509813    19.0554785893154  \n3  17.864357523914652   19.64097804287586  \n4  21.040912553984587  15.907320810732944  \n5  16.524258037845925   17.98548138095934  \n6  20.063652347231066   18.27024174892468  \n7  11.334996708770838   18.78590479935641  \n8  19.641922538006423  11.793184868148634  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results.to_csv('results.csv')",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# EOF"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}