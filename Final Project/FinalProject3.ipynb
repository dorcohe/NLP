{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,  DataLoader\nimport torch\nfrom pytorch_transformers import *\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfrom pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\nprint(device)\nimport math\nfrom scipy import spatial\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\n",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "cuda\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import csv\nSemEval_prefix = \"SemEval_\"\nimport pandas as pd\nimport numpy as np\n\nclass Parse_data:\n\n    def  __init__ (self, file_path, testing_emotions_path):\n        self.file_path = file_path\n        self.testing_emotions_path = testing_emotions_path\n        self.sem_eval2007_id_to_emotions = self.get_sem_eval2007_id_to_emotions()\n        self.data_from_file = pd.read_csv(self.file_path) \n        self.words_to_ix = self.get_words_to_ix()\n        self.normalize_data()\n        self.train_data()\n\n    def get_words_to_ix(self):\n        results = set()\n        dict = {}\n        self.data_from_file['text'].str.split().apply(results.update)\n        for i, word in enumerate(results):\n            dict.update({word : i})\n        return dict\n        \n        \n    def train_data(self):\n        \n        boolean_indexes = self.data_from_file[\"id\"].str.startswith(SemEval_prefix)\n        self.train_instances = self.data_from_file[~boolean_indexes]\n        self.test_instances = self.data_from_file[boolean_indexes]\n\n        extra_column = [np.nan] * len(self.test_instances)\n        self.test_instances.insert(5, \"Categorial\", extra_column, True)\n\n        for index in self.sem_eval2007_id_to_emotions:\n            value = self.sem_eval2007_id_to_emotions[index]\n            self.test_instances.loc[self.test_instances.id == SemEval_prefix + str(index), \"Categorial\"] = [value]\n\n        self.test_instances = self.test_instances.dropna(axis=0, how='any')\n\n        train_instances = list(range(len(self.train_instances)))\n        self.train_instances.reindex(train_instances)\n        test_instances = list(range(len(self.test_instances)))\n        self.test_instances.reindex(test_instances)\n\n\n    def normalize_data(self):\n\n        #Train\n        #mean = self.train_instances.mean()\n        #std = self.train_instances.std()\n        maxi = self.data_from_file.max()\n        mini = self.data_from_file.min()\n\n        current_v = self.data_from_file[\"V\"]\n        normalized_v = 2*(current_v - mini[\"V\"]) / (maxi[\"V\"]-mini[\"V\"]) - 1\n        self.data_from_file[\"V\"] = normalized_v\n\n        current_a = self.data_from_file[\"A\"]\n        normalized_a =2* (current_a - mini[\"A\"]) / (maxi[\"A\"]-mini[\"A\"]) -1 \n        self.data_from_file[\"A\"] = normalized_a\n        \n        current_d = self.data_from_file[\"D\"]\n        normalized_d = 2*(current_d - mini[\"D\"]) / (maxi[\"D\"]-mini[\"D\"]) -1\n        self.data_from_file[\"D\"] = normalized_d\n\n\n    def get_train_data(self):\n        \n        return self.train_instances\n\n\n    def get_id_to_sentence_dict(self):\n        sentences = {}\n        with open(self.file_path, encoding='utf8') as csv_file:\n            csv_reader = csv.reader(csv_file, delimiter=',')\n            line_count = 0\n\n            for row in csv_reader:\n                if line_count == 0:\n                    line_count += 1\n                else:\n                    if line_count == 393:\n                        line_count += 1\n                    sentences.update({row[0]: row[1]})\n                    line_count += 1\n        return sentences\n\n    def get_sem_eval2007_id_to_emotions(self):\n        sentences = {}\n        with open(self.testing_emotions_path) as csv_file:\n            csv_reader = csv.reader(csv_file, delimiter=' ')\n\n            # row is in the form: 0: id  1: anger 2: disgust 3: fear 4: joy 5 :sadness 6: surprise\n            for row in csv_reader:\n                instance = {\n                    \"id\": row[0],\n                    \"anger\": row[1],\n                    \"disgust\": row[2],\n                    \"fear\": row[3],\n                    \"joy\": row[4],\n                    \"sadness\": row[5],\n                    \"surprise\": row[6]\n                }\n                sentences.update({row[0]: instance})\n\n        return sentences\n\n\n    def get_test_data(self):\n        return self.test_instances\n\n# reader_path = \"./corpus/reader.csv\"\n# writer_path = \"./corpus/writer.csv\"\n# raw_path = \"./corpus/raw.csv\"\n# sem2007_paths = \"./affectivetext_test.emotions.gold\"\n#\n# moss = parse_data(reader_path, writer_path, raw_path, sem2007_paths)\n#\n# a = moss.get_train_data()\n# b = moss.get_test_data()\n# a = 3",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "file_path = \"/home/ofer/emobank.csv\"\nemotions_path = \"/home/ofer/affectivetext_test.emotions.csv\"",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "parse_data_instance = Parse_data(file_path, emotions_path)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self.obj[item] = s\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class EmoBankDatabase(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, file_path, emotions_path, is_testing = False):\n        self.index_to_tensors = {}\n        parse_data_instance = Parse_data(file_path, emotions_path)\n        if is_testing:\n                self.par_data = parse_data_instance.get_test_data()\n        else:\n            self.par_data = parse_data_instance.get_train_data()\n\n    def __len__(self):\n        return len(self.par_data)\n\n    def __getitem__(self, idx):\n        item = self.par_data.iloc[idx]\n        try:\n            tens = self.index_to_tensors[idx]\n        except:\n            tens = torch.tensor([item.V, item.A, item.D])\n            self.index_to_tensors.update({idx: tens})\n        return item.text, tens",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class EmobankRnnModel(torch.nn.Module):\n    def __init__(self):\n        \"\"\"\n        In the constructor we instantiate two nn.Linear modules and assign them as\n        member variables.\n        \"\"\"\n        super(EmobankRnnModel, self).__init__()\n\n        #         self.embeddings = nn.Embedding(len(words_to_index), 20)\n        self.lstm = nn.RNN(20, 100, dropout=0.05)\n        self.linear2 = torch.nn.Linear(100, 100)\n        self.linear3 = torch.nn.Linear(100, 75)\n        self.linear4 = torch.nn.Linear(75, 75)\n        self.linear5 = torch.nn.Linear(75, 3)\n\n    def forward(self, x):\n        \"\"\"\n        In the forward function we accept a Tensor of input data and we must return\n        a Tensor of output data. We can use Modules defined in the constructor as\n        well as arbitrary operators on Tensors.\n        \"\"\"\n        hidden_layers = []\n\n        for sentence in x:\n            self.hidden = self.init_hidden()\n            lstm_out, self.hidden = self.lstm(sentence.view(len(sentence), 1, -1), self.hidden)\n            hidden_layers.append(self.hidden[0].reshape(-1))\n        x = torch.stack(hidden_layers)\n        \n        x = F.relu(self.linear2(x))\n        x = F.relu(self.linear3(x))\n        x = F.relu(self.linear4(x))\n        x = self.linear5(x)\n\n        return x\n\n    def init_hidden(self):\n        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n        hidden_a = torch.zeros(1, 1, 100).to(device)\n        hidden_b = torch.randn(1, 1, 100).to(device)\n        return hidden_a    \n        \n        hidden_a = Variable(hidden_a)\n        hidden_b = Variable(hidden_b)\n\n\n",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class EmobankGRUModel(torch.nn.Module):\n    def __init__(self):\n        \"\"\"\n        In the constructor we instantiate two nn.Linear modules and assign them as\n        member variables.\n        \"\"\"\n        super(EmobankGRUModel, self).__init__()\n\n        #         self.embeddings = nn.Embedding(len(words_to_index), 20)\n        self.lstm = nn.GRU(20, 100, dropout=0.05)\n        self.linear2 = torch.nn.Linear(100, 100)\n        self.linear3 = torch.nn.Linear(100, 75)\n        self.linear4 = torch.nn.Linear(75, 75)\n        self.linear5 = torch.nn.Linear(75, 3)\n\n    def forward(self, x):\n        \"\"\"\n        In the forward function we accept a Tensor of input data and we must return\n        a Tensor of output data. We can use Modules defined in the constructor as\n        well as arbitrary operators on Tensors.\n        \"\"\"\n        hidden_layers = []\n\n        for sentence in x:\n            self.hidden = self.init_hidden()\n            lstm_out, self.hidden = self.lstm(sentence.view(len(sentence), 1, -1), self.hidden)\n            hidden_layers.append(self.hidden[0].reshape(-1))\n        x = torch.stack(hidden_layers)\n        \n        x = F.relu(self.linear2(x))\n        x = F.relu(self.linear3(x))\n        x = F.relu(self.linear4(x))\n        x = self.linear5(x)\n\n        return x\n\n    def init_hidden(self):\n        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n        hidden_a = torch.zeros(1, 1, 100).to(device)\n        hidden_b = torch.randn(1, 1, 100).to(device)\n        return hidden_a    \n        \n        hidden_a = Variable(hidden_a)\n        hidden_b = Variable(hidden_b)\n\n\n",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class EmobankLSTMModel(torch.nn.Module):\n    def __init__(self):\n        \"\"\"\n        In the constructor we instantiate two nn.Linear modules and assign them as\n        member variables.\n        \"\"\"\n        super(EmobankLSTMModel, self).__init__()\n\n        #         self.embeddings = nn.Embedding(len(words_to_index), 20)\n        self.lstm = nn.LSTM(20, 100, dropout=0.05)\n        self.linear2 = torch.nn.Linear(100, 100)\n        self.linear3 = torch.nn.Linear(100, 75)\n        self.linear4 = torch.nn.Linear(75, 75)\n        self.linear5 = torch.nn.Linear(75, 3)\n\n    def forward(self, x):\n        \"\"\"\n        In the forward function we accept a Tensor of input data and we must return\n        a Tensor of output data. We can use Modules defined in the constructor as\n        well as arbitrary operators on Tensors.\n        \"\"\"\n        hidden_layers = []\n\n        for sentence in x:\n            self.hidden = self.init_hidden()\n            lstm_out, self.hidden = self.lstm(sentence.view(len(sentence), 1, -1), self.hidden)\n            hidden_layers.append(self.hidden[0].reshape(-1))\n        x = torch.stack(hidden_layers)\n        \n        x = F.relu(self.linear2(x))\n        x = F.relu(self.linear3(x))\n        x = F.relu(self.linear4(x))\n        x = self.linear5(x)\n\n        return x\n\n    def init_hidden(self):\n        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n        hidden_a = torch.zeros(1, 1, 100).to(device)\n        hidden_b = torch.randn(1, 1, 100).to(device)\n        \n        return (hidden_a, hidden_b)\n\n\n",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class EmobankFineTuningBERTModule(torch.nn.Module):\n    def __init__(self, model_class):\n        \"\"\"\n        In the constructor we instantiate two nn.Linear modules and assign them as\n        member variables.\n        \"\"\"\n        super(EmobankFineTuningBERTModule, self).__init__()\n\n        self.bert = model_class\n        self.linear2 = torch.nn.Linear(768, 100)\n        self.linear3 = torch.nn.Linear(100, 75)\n        self.linear4 = torch.nn.Linear(75, 75)\n        self.linear5 = torch.nn.Linear(75, 3)\n\n    def forward(self, x):\n        \"\"\"\n        In the forward function we accept a Tensor of input data and we must return\n        a Tensor of output data. We can use Modules defined in the constructor as\n        well as arbitrary operators on Tensors.\n        \"\"\"\n        x = [get_all_hidden_states(instance, self.bert) for instance in x]\n        x = [self.linear2(instance.view(-1, 768)) for instance in x]\n        x = [torch.mean(instance, dim=0) for instance in x]\n        x = torch.stack(x, dim=0, out=None)\n        \n        x = F.relu(self.linear3(x))\n        x = F.relu(self.linear4(x))\n        x = self.linear5(x)\n\n        \n        \n        return x",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_all_hidden_states(x, model):\n    all_hidden_states, all_attentions = model(x)[-2:]\n\n    return all_hidden_states[0]\n\n\ndef get_all_hidden_states(x, model):\n    all_hidden_states, all_attentions = model(x)[-2:]\n\n    return all_hidden_states[0]\n\ndef prepare_sequence(seq, to_ix, embeddings):\n    seq = seq.split()\n    idxs = [to_ix[w] for w in seq]\n    return embeddings(torch.tensor(idxs, dtype=torch.long))\n\n\n\ndef Train_Net_sequencial(my_net, trainloader, criterion):\n    optimizer = torch.optim.SGD(my_net.parameters(), lr=0.01, momentum=0.9)\n\n    embeddings = nn.Embedding(len(parse_data_instance.words_to_ix), 20)\n\n    # training loop\n    for epoch in range(1000):\n        if epoch > 0:\n            #path = \"C:\\\\IDCMaster\\\\DeepLearning\\\\projectNotebook\\\\modelCosinev7\" + str(epoch + 83)\n            #path2 = \"C:\\\\IDCMaster\\\\DeepLearning\\\\projectNotebook\\\\tokinezerv\" + str(epoch + 83)\n            #torch.save(my_net, path)\n            print(\"Avg epoch loss for training data: \" + str(epoch_loss / len(trainloader)))\n        epoch_loss = 0.0\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs\n\n            inputs, labels = data\n\n            inputs = [prepare_sequence(sentence, parse_data_instance.words_to_ix, embeddings) for sentence in inputs]\n\n            labels = labels.to(device)\n            #             embedded_input = [torch.tensor([tokenizer.encode(text)]).to(device) for text in inputs]\n\n            # flags = Variable(torch.ones(len(embedded_input))).to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = my_net(inputs)\n            # loss = torch.mean(torch.sqrt(torch.sum((outputs - labels) ** 2,  dim=1))).to(device)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_loss += loss.item()\n\n        # After every epoch, measure the testing\n        sum_loss = 0.0\n        for i, data in enumerate(dataloader_testing, 0):\n            # get the inputs\n            inputs, labels = data\n            labels = labels.to(device)\n            # embedded_input = [torch.tensor([tokenizer.encode(text)]).to(device) for text in inputs]\n            my_net.eval()\n            inputs = [prepare_sequence(sentence, parse_data_instance.words_to_ix, embeddings) for sentence in inputs]\n            outputs = my_net(inputs)\n            # flags = Variable(torch.ones(len(embedded_input))).to(device)\n            loss = criterion(outputs, labels)\n            sum_loss = sum_loss + loss.item()\n        print(\"finished epoch \" + str(epoch) + \" with avarage sum_loss on testing data = \" + str(sum_loss / i))\n\n    return my_net\n\n\ndef Train_Net_BERT(my_net, trainloader, criterion):\n   #optimizer = torch.optim.SGD(my_net.parameters(), lr=0.01, momentum=0.9)\n    optimizer = BertAdam(my_net.parameters(), lr=0.001, schedule='warmup_linear', warmup=0.1, t_total=23000000)\n    print(device)\n\n    # training loop\n    for epoch in range(1000):\n        if epoch > 0:\n            #path = \"/home/ofer/model\" + str(epoch+83)\n            #path2 = \"/home/ofer/tokinezer\" + str(epoch+83)\n            #torch.save(my_net, path) \n            #torch.save(tokenizer, path2) \n            print(\"Avg epoch loss for training data: \" + str(epoch_loss/len(trainloader)))\n        epoch_loss = 0.0\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n            if (i%1000 == 0):\n                print(i)\n            # get the inputs\n            inputs, labels = data\n                \n            labels = labels.to(device)\n            embedded_input = [torch.tensor([tokenizer.encode(text)]).to(device) for text in inputs]\n                \n            #flags = Variable(torch.ones(len(embedded_input))).to(device)\n\n            # forward + backward + optimize\n            outputs = my_net(embedded_input)\n            #loss = torch.mean(torch.sqrt(torch.sum((outputs - labels) ** 2,  dim=1))).to(device) \n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            \n            # print statistics\n            running_loss += loss.item()\n            epoch_loss += loss.item()\n            \n        # After every epoch, measure the testing\n        sum_loss = 0.0\n        for i, data in enumerate(dataloader_testing, 0):\n            # get the inputs\n            inputs, labels = data\n            labels = labels.to(device)\n            embedded_input = [torch.tensor([tokenizer.encode(text)]).to(device) for text in inputs]\n            my_net.eval()\n            #inputs = [prepare_sequence(sentence, parse_data_instance.words_to_ix, embeddings) for sentence in inputs]\n            outputs = my_net(embedded_input)\n            # flags = Variable(torch.ones(len(embedded_input))).to(device)\n            loss = criterion(outputs, labels)\n            sum_loss = sum_loss + loss.item()\n        print(\"finished epoch \" + str(epoch) + \" with avarage sum_loss on testing data = \" + str(sum_loss / i))\n\n    return my_net\n\n",
      "execution_count": 56,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\n\n##########################################################################\n\n\n\n########################################################################## Set  basic parameters\n\nfile_path = \"/home/ofer/emobank.csv\"\nemotions_path = \"/home/ofer/affectivetext_test.emotions.csv\"\n\n\n\nMODELS = [(BertModel,       BertTokenizer,      'bert-base-uncased'),\n          (OpenAIGPTModel,  OpenAIGPTTokenizer, 'openai-gpt'),\n          (GPT2Model,       GPT2Tokenizer,      'gpt2'),\n          (TransfoXLModel,  TransfoXLTokenizer, 'transfo-xl-wt103'),\n          (XLNetModel,      XLNetTokenizer,     'xlnet-base-cased'),\n          (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024')]\n\nmodel_class, tokenizer_class, pretrained_weights = MODELS[0]",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_dataset_training = EmoBankDatabase(file_path , emotions_path)\nemobank_dataset_training\n    \n\ndataloader_training = DataLoader(emobank_dataset_training, batch_size=4,\n                            shuffle=True, num_workers=6)",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self.obj[item] = s\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_dataset_testing = EmoBankDatabase(file_path , emotions_path, True)\ndataloader_testing = DataLoader(emobank_dataset_testing, batch_size=1,\n                        shuffle=True, num_workers=6)\n\nnumber_of_instances = len(emobank_dataset_testing)",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self.obj[item] = s\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "parse_data_instance = Parse_data(file_path, emotions_path)",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self.obj[item] = s\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(parse_data_instance.words_to_ix)",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "28931"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def prepare_sequence(seq, to_ix, embeddings):\n    seq = seq.split()\n    idxs = [to_ix[w] for w in seq]\n    return embeddings(torch.tensor(idxs, dtype=torch.long))",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test = parse_data_instance.get_test_data()",
      "execution_count": 46,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "criterion = nn.MSELoss()\nbert_model = BertModel.from_pretrained(pretrained_weights).to(device)\nemobank_fine_tuning_bert_module = EmobankFineTuningBERTModule(bert_model).to(device)\ntokenizer = tokenizer_class.from_pretrained(pretrained_weights)",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_fine_tuning_bert_module = Train_Net_BERT(emobank_fine_tuning_bert_module, dataloader_training, criterion)\n\n\n\n\n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "cuda\n0\n1000\n2000\nfinished epoch 0 with avarage sum_loss on testing data = 0.042717748653496077\nAvg epoch loss for training data: 0.032285347636545544\n0\n1000\n2000\nfinished epoch 1 with avarage sum_loss on testing data = 0.03718980227517812\nAvg epoch loss for training data: 0.026710756878873268\n0\n1000\n2000\nfinished epoch 2 with avarage sum_loss on testing data = 0.03607948807056853\nAvg epoch loss for training data: 0.02179707068333955\n0\n1000\n2000\nfinished epoch 3 with avarage sum_loss on testing data = 0.03527036522615647\nAvg epoch loss for training data: 0.01747157207981585\n0\n1000\n2000\nfinished epoch 4 with avarage sum_loss on testing data = 0.03627000008590814\nAvg epoch loss for training data: 0.013335979469252768\n0\n1000\n2000\nfinished epoch 5 with avarage sum_loss on testing data = 0.037463997056793624\nAvg epoch loss for training data: 0.009798168360190155\n0\n1000\n2000\nfinished epoch 6 with avarage sum_loss on testing data = 0.03716644827416682\nAvg epoch loss for training data: 0.0071792552582823025\n0\n1000\n2000\nfinished epoch 7 with avarage sum_loss on testing data = 0.037467840355716375\nAvg epoch loss for training data: 0.005417651189387229\n0\n1000\n2000\nfinished epoch 8 with avarage sum_loss on testing data = 0.037263315725494184\nAvg epoch loss for training data: 0.0046383814708650115\n0\n1000\n2000\nfinished epoch 9 with avarage sum_loss on testing data = 0.03643040098643496\nAvg epoch loss for training data: 0.0041112958542455485\n0\n1000\n2000\nfinished epoch 10 with avarage sum_loss on testing data = 0.03591836645382663\nAvg epoch loss for training data: 0.004056125064236128\n0\n1000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_gru_module = EmobankGRUModel().to(device)",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n  \"num_layers={}\".format(dropout, num_layers))\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_gru_module = Train_Net_sequencial(emobank_gru_module, dataloader_training, criterion)\n",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "finished epoch 0 with avarage sum_loss on testing data = 0.04212493491660827\nAvg epoch loss for training data: 0.03780677252632991\nfinished epoch 1 with avarage sum_loss on testing data = 0.0434301919551631\nAvg epoch loss for training data: 0.03769670416972888\nfinished epoch 2 with avarage sum_loss on testing data = 0.04690990026586849\nAvg epoch loss for training data: 0.03755955674505837\nfinished epoch 3 with avarage sum_loss on testing data = 0.044082009621375845\nAvg epoch loss for training data: 0.03769106678714732\nfinished epoch 4 with avarage sum_loss on testing data = 0.04490167645585293\nAvg epoch loss for training data: 0.03759821525216871\nfinished epoch 5 with avarage sum_loss on testing data = 0.044748333609565795\nAvg epoch loss for training data: 0.03747993860095678\nfinished epoch 6 with avarage sum_loss on testing data = 0.044457777898067825\nAvg epoch loss for training data: 0.037464205428048306\nfinished epoch 7 with avarage sum_loss on testing data = 0.041857097779699474\nAvg epoch loss for training data: 0.037507909773985285\nfinished epoch 8 with avarage sum_loss on testing data = 0.04556463206430639\nAvg epoch loss for training data: 0.03735544315536126\nfinished epoch 9 with avarage sum_loss on testing data = 0.04592592138119898\nAvg epoch loss for training data: 0.03725294752601457\nfinished epoch 10 with avarage sum_loss on testing data = 0.04301991068941587\nAvg epoch loss for training data: 0.03710762083904925\nfinished epoch 11 with avarage sum_loss on testing data = 0.04819969922028817\nAvg epoch loss for training data: 0.03701796633985008\nfinished epoch 12 with avarage sum_loss on testing data = 0.04324901068855584\nAvg epoch loss for training data: 0.036994319513489395\nfinished epoch 13 with avarage sum_loss on testing data = 0.041351017835583134\nAvg epoch loss for training data: 0.03675885975377473\nfinished epoch 14 with avarage sum_loss on testing data = 0.049486632638886176\nAvg epoch loss for training data: 0.03651261617303074\nfinished epoch 15 with avarage sum_loss on testing data = 0.04539849493809203\nAvg epoch loss for training data: 0.036535039496929926\nfinished epoch 16 with avarage sum_loss on testing data = 0.04277100042174168\nAvg epoch loss for training data: 0.036108874416995264\nfinished epoch 17 with avarage sum_loss on testing data = 0.04644554236428925\nAvg epoch loss for training data: 0.03592376553563153\nfinished epoch 18 with avarage sum_loss on testing data = 0.04566196977233615\nAvg epoch loss for training data: 0.03542917156602552\nfinished epoch 19 with avarage sum_loss on testing data = 0.045771928690508834\nAvg epoch loss for training data: 0.03522066257558681\nfinished epoch 20 with avarage sum_loss on testing data = 0.04268337372805198\nAvg epoch loss for training data: 0.034649157463225035\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-6c183e425129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memobank_gru_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_Net_sequencial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memobank_gru_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-0600909027aa>\u001b[0m in \u001b[0;36mTrain_Net_sequencial\u001b[0;34m(my_net, trainloader, criterion)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;31m# loss = torch.mean(torch.sqrt(torch.sum((outputs - labels) ** 2,  dim=1))).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e7fd3bdb397b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mhidden_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mrun_impl\u001b[0;34m(self, input, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             result = _VF.gru(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 679\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_rnn_module = EmobankRnnModel().to(device)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n  \"num_layers={}\".format(dropout, num_layers))\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_rnn_module = Train_Net_sequencial(emobank_rnn_module, dataloader_training, criterion)",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "finished epoch 0 with avarage sum_loss on testing data = 0.04753585378778019\nAvg epoch loss for training data: 0.03788075814187003\nfinished epoch 1 with avarage sum_loss on testing data = 0.0488085781277116\nAvg epoch loss for training data: 0.0376554570584926\nfinished epoch 2 with avarage sum_loss on testing data = 0.04425725227836615\nAvg epoch loss for training data: 0.03749830334138092\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-637c2bf9b3b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memobank_rnn_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_Net_sequencial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memobank_rnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-0600909027aa>\u001b[0m in \u001b[0;36mTrain_Net_sequencial\u001b[0;34m(my_net, trainloader, criterion)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# loss = torch.mean(torch.sqrt(torch.sum((outputs - labels) ** 2,  dim=1))).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_lstm_module = EmobankLSTMModel().to(device)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n  \"num_layers={}\".format(dropout, num_layers))\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "emobank_lstm_module = Train_Net_sequencial(emobank_lstm_module, dataloader_training, criterion)",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "finished epoch 0 with avarage sum_loss on testing data = 0.04205203087481761\nAvg epoch loss for training data: 0.03786249024449526\nfinished epoch 1 with avarage sum_loss on testing data = 0.045893294863892056\nAvg epoch loss for training data: 0.03775530279211196\nfinished epoch 2 with avarage sum_loss on testing data = 0.044866237282444536\nAvg epoch loss for training data: 0.037665797378338944\nfinished epoch 3 with avarage sum_loss on testing data = 0.04545731376329078\nAvg epoch loss for training data: 0.03780656566021411\nfinished epoch 4 with avarage sum_loss on testing data = 0.04233708896079749\nAvg epoch loss for training data: 0.03765356640064755\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-4267465a15ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memobank_lstm_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_Net_sequencial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memobank_lstm_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-0600909027aa>\u001b[0m in \u001b[0;36mTrain_Net_sequencial\u001b[0;34m(my_net, trainloader, criterion)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# loss = torch.mean(torch.sqrt(torch.sum((outputs - labels) ** 2,  dim=1))).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_instance_category(test_instance):\n    max_value_first = -1\n    max_value_second = -1\n    max_category_first = \"moss\"\n    max_category_second = \"moss\"\n    instance_categories = test_instance[\"Categorial\"]\n    for category in instance_categories:\n        if float(instance_categories[category]) > max_value_second and category != \"id\":\n            max_value_first = max_value_second\n            max_value_second = float(instance_categories[category])\n            max_category_first = max_category_second\n            max_category_second = category\n    return [max_category_first]\n    ",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_distance(a, b):\n    return (np.square(a - b)).mean(axis=None)\n#math.sqrt((current_category_vad[\"v\"] - model_output[0])**2 + (current_category_vad[\"a\"] - model_output[1])**2 + (current_category_vad[\"d\"] - model_output[2])**2)",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_category(model_output):\n    model_output = model_output[0]\n    categories_distance = []\n    for i, category in enumerate(category_to_index):\n        # index: 0:V, 1:A, 2:D\n        current_category_vad = categories_vad[category]\n        a = np.empty(3)\n        a[0] = current_category_vad[\"v\"]\n        a[1] = current_category_vad[\"a\"]\n        a[2] = current_category_vad[\"d\"]\n        distance_from_category = get_distance(a,model_output.to(\"cpu\").detach().numpy())\n        categories_distance.append(distance_from_category)\n#     print(category_to_index)\n#     print(categories_distance)\n    return index_to_catogory[categories_distance.index(min(categories_distance))]\n        ",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "categories_vad = {\n    \"joy\":{\n        \"v\":0.76,\n        \"a\":0.48,\n        \"d\":0.35\n    },\n    \"anger\":{\n        \"v\":-0.51,\n        \"a\":0.59,\n        \"d\":0.25\n    },\n      \"sadness\":{\n        \"v\":-0.63,\n        \"a\":-0.27,\n        \"d\":-0.33\n    },\n      \"fear\":{\n        \"v\":-0.64,\n        \"a\":0.6,\n        \"d\":-0.43\n    },\n      \"disgust\":{\n        \"v\":-0.6,\n        \"a\":0.35,\n        \"d\":0.11\n    },\n    \"surprise\":{\n        \"v\":0.4,\n        \"a\":0.67,\n        \"d\":-0.13\n    }\n}\n\n\nindex_to_catogory = {\n    0 : \"joy\",\n    1 : \"anger\",\n    2 : \"sadness\",\n    3 : \"fear\",\n    4 : \"disgust\",\n    5 : \"surprise\",\n}\n\ncategory_to_index = [\"joy\", \"anger\", \"sadness\", \"fear\", \"disgust\", \"surprise\"]\n",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "\ntotal_count = 0\ncorrect_count = 0\n    \nfor i, test_insance in test.iterrows():\n    text = test_insance[\"text\"]\n    embeded_text = torch.tensor([tokenizer.encode(text)]).to(device)\n    outputs = model([embeded_text])\n\n\n    category = get_category(outputs)\n    instance_actual_category = get_instance_category(test_insance)\n\n    if category in instance_actual_category:\n        correct_count += 1 \n    total_count += 1\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(\"correctness: \" + str(correct_count / total_count))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}